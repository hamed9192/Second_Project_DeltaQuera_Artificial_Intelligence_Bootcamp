{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f35f4e",
   "metadata": {},
   "source": [
    "<p style='color:red ; font-size:32px; text-align:center;' dir=rtl>\n",
    "سوال دوم \n",
    "<br>\n",
    "قسمت سوم : تحلیل احساس نظرات\n",
    "<br>\n",
    "با استفاده از مدل RoBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbf1311",
   "metadata": {},
   "source": [
    "<p style='color:yellow ; font-size:28px; text-align:center;' dir=rtl>\n",
    "وارد کردن توابع مورد نیاز"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e71abc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\M.H.A\\anaconda3\\envs\\sentiment_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification \n",
    "from tqdm.auto import tqdm\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090e6556",
   "metadata": {},
   "source": [
    "<p style='color:yellow ; font-size:28px; text-align:center;' dir=rtl>\n",
    "1. تنظیمات عمومی"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f97b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "استفاده از دستگاه: cuda\n",
      "نام GPU: NVIDIA GeForce RTX 2060\n",
      "حافظه GPU (کلی): 6.00 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. تنظیمات عمومی ---\n",
    "MODEL_NAME = 'roberta-base' # 🌟 تغییر اصلی: نام مدل به roberta-base\n",
    "MAX_LEN = 128                 \n",
    "BATCH_SIZE = 16               \n",
    "NUM_EPOCHS = 3                \n",
    "LEARNING_RATE = 2e-5          \n",
    "\n",
    "# --- تشخیص دستگاه (CPU یا GPU) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"استفاده از دستگاه: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"نام GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"حافظه GPU (کلی): {torch.cuda.get_device_properties(0).total_memory / (1024**3):.2f} GB\")\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME) \n",
    "model = RobertaForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=5) \n",
    "model.to(device) # انتقال مدل به GPU (اگر موجود باشد)\n",
    "\n",
    "# --- کلاس برای نگهداری ورودی‌های توکن‌سازی شده ---\n",
    "@dataclass\n",
    "class EncodedData:\n",
    "    input_ids: torch.Tensor\n",
    "    attention_mask: torch.Tensor\n",
    "    labels: torch.Tensor = None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d97380d",
   "metadata": {},
   "source": [
    "<p style='color:yellow ; font-size:28px; text-align:center;' dir=rtl>\n",
    "2. کلاس Dataset برای داده‌های آموزش (با لیبل) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f643e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. کلاس Dataset برای داده‌های آموزش (با لیبل) ---\n",
    "class TrainReviewDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings \n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "            'input_ids': self.encodings['input_ids'][item].flatten(),\n",
    "            'attention_mask': self.encodings['attention_mask'][item].flatten(),\n",
    "            'labels': torch.tensor(self.labels[item] - 1, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e05a84",
   "metadata": {},
   "source": [
    "<p style='color:yellow ; font-size:28px; text-align:center;' dir=rtl>\n",
    "3. کلاس Dataset برای داده‌های پیش بینی (بدون لیبل) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34206d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. کلاس Dataset برای داده‌های پیش‌بینی (بدون لیبل) ---\n",
    "class PredictReviewDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "            'input_ids': self.encodings['input_ids'][item].flatten(),\n",
    "            'attention_mask': self.encodings['attention_mask'][item].flatten(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baab8e5",
   "metadata": {},
   "source": [
    "<p style='color:yellow ; font-size:28px; text-align:center;' dir=rtl>\n",
    "4. تابع بارگذاری و پیش‌پردازش داده از فایل‌ها "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f753567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. تابع بارگذاری و پیش‌پردازش داده از فایل‌ها ---\n",
    "def load_and_preprocess_data_for_training_and_prediction(train_file_path, predict_file_path, text_col='reviewText', target_col='overall'):\n",
    "    try:\n",
    "        temp_train_df = pd.read_csv(train_file_path)\n",
    "        \n",
    "        #  30000 سطر تصادفی از آن را انتخاب می‌کنیم\n",
    "        # اگر تعداد کل سطرها کمتر از 30000 باشد، همه سطرها انتخاب می‌شوند.\n",
    "        train_df = temp_train_df.sample(n=min(30000, len(temp_train_df)), random_state=42) \n",
    "        predict_df = pd.read_csv(predict_file_path) \n",
    "        \n",
    "        print(f\"✅ داده‌های آموزش از '{train_file_path}' با موفقیت بارگذاری شد. تعداد ردیف‌ها: {len(train_df)}\")\n",
    "        print(f\"✅ داده‌های پیش‌بینی از '{predict_file_path}' با موفقیت بارگذاری شد. تعداد ردیف‌ها: {len(predict_df)}\")\n",
    "        \n",
    "        train_df.dropna(subset=[text_col, target_col], inplace=True)\n",
    "        train_df[text_col] = train_df[text_col].astype(str)\n",
    "        train_df[target_col] = train_df[target_col].astype(int)\n",
    "        \n",
    "        predict_df.dropna(subset=[text_col], inplace=True) \n",
    "        predict_df[text_col] = predict_df[text_col].astype(str)\n",
    "        \n",
    "        return train_df, predict_df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ خطا: یکی از فایل‌ها یافت نشد. لطفاً مسیر فایل‌ها را بررسی کنید.\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ خطا در بارگذاری یا پیش‌پردازش فایل: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03db9b7d",
   "metadata": {},
   "source": [
    " <p style='color:yellow ; font-size:28px; text-align:center;' dir=rtl>\n",
    "تابع جدید: توکن‌سازی دسته‌ای در ابتدای کار\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f17cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- تابع جدید: توکن‌سازی دسته‌ای در ابتدای کار ---\n",
    "def tokenize_data_batch(texts, tokenizer, max_len):\n",
    "    print(\"\\n⏳ در حال توکن‌سازی داده‌ها (این ممکن است کمی طول بکشد)...\")\n",
    "    encodings = tokenizer.batch_encode_plus(\n",
    "        texts.tolist(), \n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "        truncation=True\n",
    "    )\n",
    "    print(\"✅ توکن‌سازی داده‌ها با موفقیت انجام شد.\")\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb3863",
   "metadata": {},
   "source": [
    " <p style='color:yellow ; font-size:28px; text-align:center;' dir=rtl>\n",
    " 5. تابع ساخت DataLoaderها (با داده‌های از پیش توکن‌سازی شده) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bece88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. تابع ساخت DataLoaderها (با داده‌های از پیش توکن‌سازی شده) ---\n",
    "def create_data_loaders(train_df, predict_df, tokenizer, max_len, batch_size):\n",
    "    if train_df is None or predict_df is None:\n",
    "        return None, None\n",
    "\n",
    "    train_encodings = tokenize_data_batch(train_df.reviewText, tokenizer, max_len)\n",
    "    predict_encodings = tokenize_data_batch(predict_df.reviewText, tokenizer, max_len)\n",
    "\n",
    "    train_dataset = TrainReviewDataset(\n",
    "        encodings=train_encodings,\n",
    "        labels=train_df.overall.to_numpy()\n",
    "    )\n",
    "\n",
    "    predict_dataset = PredictReviewDataset(\n",
    "        encodings=predict_encodings\n",
    "    )\n",
    "\n",
    "    train_data_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0 \n",
    "    )\n",
    "\n",
    "    predict_data_loader = DataLoader(\n",
    "        predict_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0 \n",
    "    )\n",
    "    \n",
    "    print(f\"\\nتعداد دسته‌های آموزش: {len(train_data_loader)}\")\n",
    "    print(f\"تعداد دسته‌های پیش‌بینی: {len(predict_data_loader)}\")\n",
    "    return train_data_loader, predict_data_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255f035f",
   "metadata": {},
   "source": [
    " <p style='color:yellow ; font-size:28px; text-align:center;' dir=rtl>\n",
    " 6. تابع آموزش یک Epoch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1953cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. تابع آموزش یک Epoch ---\n",
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    model.train() \n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for d in tqdm(data_loader, desc=\"Training\"):\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        labels = d[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels \n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        \n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        loss.backward() \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) \n",
    "        optimizer.step() \n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / total_samples, sum(losses) / len(losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f6174a",
   "metadata": {},
   "source": [
    " <p style='color:yellow ; font-size:28px; text-align:center;' dir=rtl>\n",
    "7. تابع پیش‌بینی روی داده‌های جدید (بدون لیبل) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ccaddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. تابع پیش‌بینی روی داده‌های جدید (بدون لیبل) ---\n",
    "def predict_on_new_data(model, data_loader, device):\n",
    "    model.eval() \n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for d in tqdm(data_loader, desc=\"Predicting\"):\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            logits = outputs.logits\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            \n",
    "            all_predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "    return [p + 1 for p in all_predictions] \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54c6da8",
   "metadata": {},
   "source": [
    " <p style='color:yellow ; font-size:28px; text-align:center;' dir=rtl>\n",
    " 8. تابع اصلی برای اجرای همه مراحل "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e09a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. تابع اصلی برای اجرای همه مراحل ---\n",
    "def run_deep_learning_sentiment_prediction(train_file_path, predict_file_path, text_col='reviewText', target_col='overall'):\n",
    "    train_df, predict_df = load_and_preprocess_data_for_training_and_prediction(train_file_path, predict_file_path, text_col=text_col, target_col=target_col)\n",
    "\n",
    "    if train_df is None or predict_df is None:\n",
    "        print(\"🚨 بارگذاری داده‌ها با خطا مواجه شد. برنامه متوقف می‌شود.\")\n",
    "        return\n",
    "\n",
    "    train_data_loader, predict_data_loader = create_data_loaders(\n",
    "        train_df, predict_df, tokenizer, MAX_LEN, BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    print(\"\\n--- شروع آموزش مدل ---\")\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"\\n--- Epoch {epoch + 1}/{NUM_EPOCHS} ---\")\n",
    "        train_acc, train_loss = train_epoch(\n",
    "            model,\n",
    "            train_data_loader,\n",
    "            optimizer,\n",
    "            device\n",
    "        )\n",
    "        print(f\"✨ آموزش - دقت: {train_acc:.4f}, خطا: {train_loss:.4f}\")\n",
    "\n",
    "    print(\"\\n--- آموزش مدل به پایان رسید. شروع پیش‌بینی روی داده‌های جدید ---\")\n",
    "    \n",
    "    predicted_ratings = predict_on_new_data(model, predict_data_loader, device)\n",
    "\n",
    "    submission_df = pd.DataFrame({'predicted': predicted_ratings})\n",
    "    \n",
    "    output_file_path = 'q2_submission.csv'\n",
    "    submission_df.to_csv(output_file_path, index=False) \n",
    "\n",
    "    print(f\"\\n🎉 پیش‌بینی‌ها با موفقیت در فایل '{output_file_path}' ذخیره شدند.\")\n",
    "    print(\"📋 ۱۰ ردیف اول فایل ارسالی:\")\n",
    "    print(submission_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa01ba1",
   "metadata": {},
   "source": [
    " <p style='color:yellow ; font-size:28px; text-align:center;' dir=rtl>\n",
    " اجرای اسکریپت نهایی"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51074e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\ipykernel_7420\\1440439958.py:4: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_train_df = pd.read_csv(train_file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ داده‌های آموزش از 'train_data.csv' با موفقیت بارگذاری شد. تعداد ردیف‌ها: 30000\n",
      "✅ داده‌های پیش‌بینی از 'test_data.csv' با موفقیت بارگذاری شد. تعداد ردیف‌ها: 20000\n",
      "\n",
      "⏳ در حال توکن‌سازی داده‌ها (این ممکن است کمی طول بکشد)...\n",
      "✅ توکن‌سازی داده‌ها با موفقیت انجام شد.\n",
      "\n",
      "⏳ در حال توکن‌سازی داده‌ها (این ممکن است کمی طول بکشد)...\n",
      "✅ توکن‌سازی داده‌ها با موفقیت انجام شد.\n",
      "\n",
      "تعداد دسته‌های آموزش: 1875\n",
      "تعداد دسته‌های پیش‌بینی: 1250\n",
      "\n",
      "--- شروع آموزش مدل ---\n",
      "\n",
      "--- Epoch 1/3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [18:04<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✨ آموزش - دقت: 0.6781, خطا: 0.8164\n",
      "\n",
      "--- Epoch 2/3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [18:17<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✨ آموزش - دقت: 0.7353, خطا: 0.6618\n",
      "\n",
      "--- Epoch 3/3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1875/1875 [18:02<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✨ آموزش - دقت: 0.7785, خطا: 0.5641\n",
      "\n",
      "--- آموزش مدل به پایان رسید. شروع پیش‌بینی روی داده‌های جدید ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1250/1250 [02:13<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 پیش‌بینی‌ها با موفقیت در فایل 'q2_submission.csv' ذخیره شدند.\n",
      "📋 ۱۰ ردیف اول فایل ارسالی:\n",
      "   predicted\n",
      "0          1\n",
      "1          1\n",
      "2          1\n",
      "3          1\n",
      "4          1\n",
      "5          1\n",
      "6          1\n",
      "7          1\n",
      "8          1\n",
      "9          2\n"
     ]
    }
   ],
   "source": [
    "# --- اجرای اسکریپت ---\n",
    "if __name__ == \"__main__\":\n",
    "    train_csv_file_path = 'train_data.csv' \n",
    "    predict_csv_file_path = 'test_data.csv' \n",
    "    \n",
    "    run_deep_learning_sentiment_prediction(\n",
    "        train_csv_file_path, \n",
    "        predict_csv_file_path, \n",
    "        text_col='reviewText', \n",
    "        target_col='overall'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e82c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مدل و توکنایزر آموزش‌دیده با موفقیت در مسیر 'roberta_sentiment_model_trained' ذخیره شدند.\n"
     ]
    }
   ],
   "source": [
    "# --- کد ذخیره مدل در اینجا اضافه می‌شود ---\n",
    "# نام پوشه‌ای که مدل در آن ذخیره می‌شود\n",
    "output_dir = \"roberta_sentiment_model_trained\" \n",
    "\n",
    "# مطمئن می‌شویم که پوشه خروجی وجود دارد\n",
    "import os\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "# ذخیره مدل (وزن‌ها و پیکربندی)\n",
    "model_to_save = model.module if hasattr(model, 'module') else model \n",
    "model_to_save.save_pretrained(output_dir)\n",
    "\n",
    "# ذخیره توکنایزر\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"مدل و توکنایزر آموزش‌دیده با موفقیت در مسیر '{output_dir}' ذخیره شدند.\") # تغییر به print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20074fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
